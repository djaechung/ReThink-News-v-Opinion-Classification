{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c5f193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "prelim_data = pd.read_csv('Full text articles_oct_nov.csv')\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e60d7f",
   "metadata": {},
   "source": [
    "# Common Opinion and News Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b8ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#possible opinion terms\n",
    "\n",
    "opinion = [\"opinion\", \n",
    "           \"analysis\",  \n",
    "           \"guest columnist\", \n",
    "           \"letter to the editor\", \n",
    "           \"letters to the editor\",\n",
    "           \"editorial\", \n",
    "           \"editor\",\n",
    "           \"column\",\n",
    "           \"editorial board\",\n",
    "           \"editors\", \n",
    "           \"readers\", \n",
    "           \"columnist\", \n",
    "           \"special\", \n",
    "           \"you\", \n",
    "          ]\n",
    "\n",
    "#possible news terms\n",
    "\n",
    "news = [\"editor\", \n",
    "        \"staff writer\",\n",
    "        \"staff writers\",\n",
    "        \"bureau\", \n",
    "        \"news\",\n",
    "        \"news service\", \n",
    "        \"contributing writer\",   \n",
    "        \"news group\",\n",
    "        \"bureau chief\",\n",
    "        \"contributed\", \n",
    "        \"compiled by\", \n",
    "        \"staff\",\n",
    "        \"editor in chief\", \n",
    "        \"editor-in-chief\", \n",
    "        \"managing editor\", \n",
    "        \"political editor\", \n",
    "        \"editor-at-large\", \n",
    "        \"correspondent\", \n",
    "        \"yesterday\", \n",
    "        \"last\", \n",
    "        \"say\"\n",
    "        \"some\", \n",
    "        \"company\", \n",
    "        \"official\", \n",
    "        \"plan\",\n",
    "        \"here\",\n",
    "        \"mr\",\n",
    "        \"associated press\", \n",
    "        \"reuters\", \n",
    "        \"report\"\n",
    "       ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b93ebc5",
   "metadata": {},
   "source": [
    "# Linguistic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc28e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linguistic features —  SENTLENGTH and TOKENLENGTH\n",
    "#hypothesis being that opinion texts, such as editorials, tend to feature longer sentences \n",
    "#art_str is the article as a String\n",
    "\n",
    "def sent_len(art_str):\n",
    "    \"\"\"\n",
    "    Returns the average sentence length measured in tokens (inverted).\n",
    "    \"\"\"\n",
    "    dots = [p for p in range(len(art_str)) if art_str[p] == \".\"]\n",
    "    sentences = [dots[i+1] - dots[i] for i in range(len(dots) - 1)]\n",
    "    return (1/np.average(sentences)) if sentences else (1/len(art_str))\n",
    "    \n",
    "def token_len(art_str):\n",
    "    \"\"\"\n",
    "    Returns the average token length measured in characters (inverted).\n",
    "    \"\"\"\n",
    "    wordList = art_str.split()\n",
    "    lengths = [len(w) for w in wordList]\n",
    "    return 1/(np.average(lengths)), np.sum(lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09be5549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linguistic features — NEGATION and NEGATIONSUFFIX \n",
    "#NEGATION — OPINION\n",
    "#NEGATIONSUFFIX — NEWS\n",
    "#hypothesis being that opinion texts tend to have more negations \n",
    "#n't is used commonly in citations or quotes\n",
    "\n",
    "negations = [\"no\", \"not\", \"none\", \"no one\", \"nobody\", \"neither\", \"nowhere\", \"nothing\", \"never\"]\n",
    "neg_suffix = \"n\\'t\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfafdc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negations_count(art_str):\n",
    "    wordList = art_str.lower().split()\n",
    "    total, suffix_total = 0, 0\n",
    "    for w in wordList:\n",
    "        if w in negations:\n",
    "            total += 1\n",
    "        if w[-3:] == neg_suffix:\n",
    "            suffix_total += 1\n",
    "    return total, suffix_total\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc75060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linguistic features — QUESTIONS, EXCLAMATIONS, COMMAS, and SEMICOLONS\n",
    "#hypothesis being that opinion texts tend to use more exclamations and (rhetorical) questions\n",
    "#exclamation marks, question marks, semicolons, and commas\n",
    "#QUESTIONS, EXCLAMATIONS, COMMAS, SEMICOLONS — OPINION\n",
    "#COMMAS — NEWS\n",
    " \n",
    "def punctuation_count(art_str):\n",
    "    \"\"\"\n",
    "    Determines the numbers of exclamation marks, question marks, semicolons, and commas,\n",
    "    as compared to other punctuation symbols. \n",
    "    \"\"\"\n",
    "    count = [0] * 5\n",
    "    for i in range(len(art_str)):\n",
    "        if art_str[i] == \"?\":\n",
    "            count[0] += 1\n",
    "        elif art_str[i] == \"!\":\n",
    "            count[1] += 1\n",
    "        elif art_str[i] == \",\":\n",
    "            count[2] += 1\n",
    "        elif art_str[i] == \";\":\n",
    "            count[3] += 1\n",
    "        elif art_str[i] == \".\":\n",
    "            count[4] += 1\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b171fd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linguistic features — CONNECTIVES (Temporal, Casual, Contrastive, Expansive)\n",
    "#hypothesis being that there are more connectives in news (aftermath of study)\n",
    "#casual, expansive, temporal, contrastive — NEWS \n",
    "\n",
    "\n",
    "casual = ['after', 'because', 'insofar as', 'by', 'in turn', 'for', 'once', 'as a result', 'hence', 'in the end', \n",
    "          'by then', 'but', 'subsequently', 'as', 'therefore', 'unless', 'thus', 'accordingly', 'so that', 'since', \n",
    "          'consequently', 'indeed', 'ultimately', 'then', 'even though', 'now that', 'finally”,”hence”,”if', 'although', \n",
    "          'so', 'thereby', 'otherwise', 'due to', 'and', 'when']\n",
    "\n",
    "contrastive = ['nor', 'in fact', 'despite', 'equally', 'by comparison', 'contrast', 'by contrast', 'but', 'separately', \n",
    "               'whereas', 'rather', 'meanwhile', 'also', 'even so', 'and', 'though', 'if', 'unlike', 'however', 'or', 'then', \n",
    "               'nevertheless', 'yet', 'even though', 'conversely', 'nonetheless', 'on the contrary', 'in contrast', 'while', \n",
    "               'likewise', 'instead', 'although', 'on the other hand', 'still', 'similarly', 'otherwise', 'actually', \n",
    "               'alternatively', 'on the one hand', 'when']\n",
    "\n",
    "temporal = [\"before\", \"after\", \"next\", \"shortly\", \"afterwards\", \"eventually\", \"firstly\", \"secondly\", \"previously\", \"meanwhile\",\n",
    "            \"finally\", \"while\", \"then\", \"earlier\", \"when\", \"initially\", \"soon\", \"suddenly\", \"until\", \"once\", \"recently\", \"already\", \"as\"]\n",
    "\n",
    "expansive = [\"also\", \"and\", \"as well as\", \"besides\", \"in addition\", \"furthermore\", \"in fact\", \"moreover\", \"additionally\",\n",
    "             \"too\", \"further\", \"or\", \"neither\", \"nor\", \"either\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2533f2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connective_count(art_str):\n",
    "    # casual, contrastive, temporal, expansive\n",
    "    connectives = [0] * 4\n",
    "    wordList = art_str.lower().split()\n",
    "    for w in wordList:\n",
    "        if w in casual:\n",
    "            connectives[0] += 1\n",
    "        elif w in contrastive:\n",
    "            connectives[1] += 1\n",
    "        elif w in temporal:\n",
    "            connectives[2] += 1\n",
    "        elif w in expansive:\n",
    "            connectives[3] += 1\n",
    "    return connectives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b011dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linguistic features — PRONOUNS outside of quotes — OPINION\n",
    "#study used first and second person only\n",
    "\n",
    "\n",
    "first_person = ['I', 'we', 'our', 'ourselves', 'us', 'me', 'my', 'mine', 'myself']\n",
    "second_person = ['you', 'yours', 'your', 'yourself', 'yourselves']\n",
    "third_person = ['he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', \n",
    "                'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33833df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pronouns_count(art_str):\n",
    "    wordList = art_str.lower().split()\n",
    "    pronoun_count = [0] * 3\n",
    "    for w in wordList:\n",
    "        if w in first_person:\n",
    "            pronoun_count[0] += 1\n",
    "        elif w in second_person:\n",
    "            pronoun_count[1] += 1\n",
    "        elif w in third_person:\n",
    "            pronoun_count[2] += 1\n",
    "    return pronoun_count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337909a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linguistic features — CITATIONS and CITATIONLENGTH — OPINION\n",
    "#hypothesis being that higher frequencies of citations are more indicative of opinion (aftermath of study)\n",
    "\n",
    "def find_citation(art_str):\n",
    "    \"\"\"\n",
    "    Returns the citation length and frequency in the article. \n",
    "    \"\"\"\n",
    "    quotes = re.findall(r'\"(.*?)\"', art_str)\n",
    "    within_quotes = collections.Counter(\" \".join(quotes).lower().split())\n",
    "    num_citations = len(quotes)\n",
    "    avg_citation_len = np.average([len(q) for q in quotes])\n",
    "    return [num_citations, avg_citation_len]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253fbf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linguistic features — MODALS — OPINION\n",
    "#hypothesis being that modal verbs are expected to be a better indicator for opinion \n",
    "#according to study, is less potent but do correspond to the genre as expected\n",
    "\n",
    "modals = [\"can\", \"must\", \"may\", \"could\", \"might\", \"should\", \"would\", \"shall\", \"ought to\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c027ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linguistic features — VERBSofSAYING (VoS) — NEWS\n",
    "#hypothesis that vos more common in news\n",
    "\n",
    "vos = ['acknowledge','affirm','allege','announce','assert','claim','comment','contend','declare','disclose',\n",
    "       'exclaim','explain','insist','mention','notify','observe','proclaim','propose','report','reveal','said','say','state',\n",
    "       'stipulate','tell','write']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7c6a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linguistic features — FUTURE_WILL — NEWS\n",
    "#frequency of the verb, \"will\" outside of quotes\n",
    "\n",
    "future_will = \"will\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a766e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linguistic features — DIGITS — OPINION\n",
    "#hypothesis being that digits are more frequent in opinion than news (aftermath of study)\n",
    "\n",
    "def count_digits(art_str):\n",
    "    \"\"\"\n",
    "    Returns the frequency of digits in a text. \n",
    "    \"\"\"\n",
    "    return len(re.findall(\"[\\d]+\",art_str))/len(art_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cd907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#complexity and finite verbs\n",
    "\n",
    "def get_finite_verbs(art_str):\n",
    "    finite_verb_tags = [\"VBD\", \"VBP\", \"VBZ\", \"MD\", \"BES\", \"HVS\"]\n",
    "    return [w for w in nlp(art_str) if w.tag_ in finite_verb_tags]\n",
    "\n",
    "def calc_complexity(art_str):\n",
    "    num_finite_verbs = len(get_finite_verbs(art_str))\n",
    "    complexity = num_finite_verbs / token_len(art_str)[1]\n",
    "    return complexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d2c199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#present and past tense frequency\n",
    "\n",
    "def present_tense_freq(finite_verbs):\n",
    "    present_verbs = [w for w in finite_verbs if w.tag_ == \"VBZ\" or w.tag_ == \"VBP\"]\n",
    "    present_tense_frequency = len(present_verbs) / len(finite_verbs)\n",
    "    return present_tense_frequency\n",
    "\n",
    "def past_tense_freq(finite_verbs):\n",
    "    past_verbs = [w for w in finite_verbs if w.tag_ == \"VBD\"]\n",
    "    past_tense_frequency = len(past_verbs) / len(finite_verbs)\n",
    "    return past_tense_frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd8e7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#interjection frequency\n",
    "\n",
    "def get_interjections(art_str):\n",
    "    interjections = [w for w in nlp(art_str) if w.pos_ == \"INTJ\"]\n",
    "    intj_freq = len(interjections) / token_len(art_str)[1]\n",
    "    return intj_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb67af47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subjectivity Dictionary\n",
    "import json\n",
    "mpqa_dict = json.load(open(\"mpqa_dict.json\", \"r\"))\n",
    "\n",
    "print(len(mpqa_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb4a60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linguistic features — SENTIMENT — OPINION\n",
    "#hypothesis being that opinion texts employ a less neutral language\n",
    "#calculated in study using MPQA Subjectivity Clues Lexicon \n",
    "\n",
    "def get_sentiment(art_str, mpqa_dict):\n",
    "    subjectivity, adjectives = 0, 0\n",
    "    words = art_str.lower().split()\n",
    "    \n",
    "    for w in words:\n",
    "        if w in mpqa_dict:  \n",
    "            if mpqa_dict[w]['pos'] == 'adj':\n",
    "                adjectives += 1\n",
    "            if mpqa_dict[w]['subj'] == 'weaksubj':\n",
    "                subjectivity += 0.1\n",
    "            if mpqa_dict[w]['subj'] == 'strongsubj':\n",
    "                subjectivity += 1\n",
    "          \n",
    "    num_words = len(words)\n",
    "    sentiment = subjectivity / num_words\n",
    "    adj_ratio = adjectives / num_words\n",
    "    \n",
    "    return subjectivity, sentiment, adjectives, adj_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc03ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_features(art_str):\n",
    "    counter = collections.Counter(art_str.lower().split())\n",
    "    num_words = sum([counter.get(w) for w in counter.keys()])\n",
    "    questions, exclamations, semicolons, commas, periods = punctuation_count(art_str)\n",
    "    first_p, second_p, third_p = 0, 0, 0\n",
    "    num_modals, num_vos = 0, 0\n",
    "    num_casual, num_temporal, num_contrastive, num_expansive = 0, 0, 0, 0\n",
    "    digits = 0\n",
    "    num_future = counter.get(\"will\") or 0\n",
    "    opinion_count, news_count = 0, 0\n",
    "    num_negation, negation_suffix = 0, 0\n",
    "    quotes = re.findall(r'\"(.*?)\"', art_str)\n",
    "    within_quotes = collections.Counter(\" \".join(quotes).lower().split())\n",
    "    num_citations = len(quotes)\n",
    "    avg_citation_len = np.average([len(q) for q in quotes]) if quotes else 0\n",
    "    sent_length = sent_len(art_str)\n",
    "    token_length = token_len(art_str)[0]\n",
    "    finite_verbs = get_finite_verbs(art_str)\n",
    "    complexity = calc_complexity(art_str)\n",
    "    present_freq = present_tense_freq(finite_verbs)\n",
    "    past_freq = past_tense_freq(finite_verbs)\n",
    "    interjection_freq = get_interjections(art_str)\n",
    "    \n",
    "    for w in counter.keys():\n",
    "        if w in vos:\n",
    "            num_vos += counter.get(w)\n",
    "        elif w in first_person:\n",
    "            first_p += counter.get(w)\n",
    "        elif w in second_person:\n",
    "            second_p += counter.get(w)\n",
    "        elif w in third_person:\n",
    "            third_p += counter.get(w)\n",
    "        elif w in modals:\n",
    "            num_modals += counter.get(w)\n",
    "        elif w in casual:\n",
    "            num_casual += counter.get(w)\n",
    "        elif w in temporal:\n",
    "            num_temporal += counter.get(w)\n",
    "        elif w in contrastive:\n",
    "            num_contrastive += counter.get(w)\n",
    "        elif w in expansive:\n",
    "            num_expansive += counter.get(w)\n",
    "        elif any(char.isdigit() for char in w):\n",
    "            digits += 1\n",
    "        elif w in opinion:\n",
    "            opinion_count += counter.get(w)\n",
    "        elif w in news:\n",
    "            news_count += counter.get(w)\n",
    "        elif \"n't\" in w:\n",
    "            negation_suffix += counter.get(w)\n",
    "        elif w in negations:\n",
    "            num_negation += counter.get(w)\n",
    "    \n",
    "    first_second_p = first_p + second_p\n",
    "            \n",
    "    ling_features = [sent_length, token_length, first_p, second_p, third_p, first_second_p, \n",
    "                    questions, exclamations, semicolons, commas, periods, \n",
    "                    num_casual, num_temporal, num_contrastive, num_expansive, \n",
    "                    digits, num_modals, num_vos, num_future, \n",
    "                    opinion_count, news_count,\n",
    "                    num_negation, negation_suffix, num_citations, avg_citation_len, num_words,\n",
    "                    complexity, present_freq, past_freq, interjection_freq]\n",
    "    \n",
    "    return ling_features\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619d479e",
   "metadata": {},
   "source": [
    "# Additional Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85141c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Labelled_VR_data_Oct2020_Jan2021_wfulltext.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322bacef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_from_terms(term_list, column, df=df):\n",
    "    \"\"\"\n",
    "    (List, series, df -> df) loop through (lower-case) list of terms, check for presence of that term in the specified column, \n",
    "    and create feature column where 1 denotes presence of the term\n",
    "    \"\"\"\n",
    "    for item in term_list:\n",
    "        df[item + \"_\" + column + \"_\" + \"feature\"] = np.where(df[column].fillna(\"\").str.lower().str.contains(item), 1, 0)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2bedc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dummy-coded (0/1) feature columns from terms lists\n",
    "df = create_feature_from_terms(name_lean_opinion, \"Media Name\")\n",
    "df = create_feature_from_terms(headline_lean_opinion, \"Headline\")\n",
    "df = create_feature_from_terms(fulltext_lean_opinion, \"Full Text\")\n",
    "df = create_feature_from_terms(name_lean_news, \"Media Name\")\n",
    "df = create_feature_from_terms(headline_lean_news, \"Headline\")\n",
    "df = create_feature_from_terms(fulltext_lean_news, \"Full Text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121fdb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Additional features\n",
    "\n",
    "#Dateline feature\n",
    "#News articles sometimes start with datelines, which are ALL CAPS\n",
    "#This checks if the article starts with at least 3 all caps letters\n",
    "df[\"upper_start_feature\"] = np.where(df[\"Full Text\"].str.contains('^[A-Z]{3,20} ', regex=True), 1, 0)\n",
    "\n",
    "#MediaName feature\n",
    "#The Hill, Associated Press and Reuters are all mainly news articles\n",
    "df[\"media_lean_news_feature\"] = np.where(df[\"Media Name\"].fillna(\"\").str.contains(\"Reuters|Associated Press|thehill|The Hill\", regex=True), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ad802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quotes at the End\n",
    "df[\"lastpara\"] = df[\"Full Text\"].str.extract(\"\\n([A-Za-z0-9\\,\\.\\;\\-\\\"# \\(\\)%]{60,}$)\")\n",
    "df[\"endquote\"] = np.where(df.lastpara.fillna(\"\").str.contains(\"\\\".{20,100}\\\"\", regex=True), \"End quote\", \"No end quote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9172f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.endquote.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c309c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"endquote\",\"news_opinion\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5858df49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.lastpara.fillna(\"\").str.contains(\"\\\".{30,100}\\\"\", regex=True)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
