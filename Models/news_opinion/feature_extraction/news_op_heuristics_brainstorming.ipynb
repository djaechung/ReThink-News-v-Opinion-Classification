{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1a377a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d9932d",
   "metadata": {},
   "source": [
    "# Loading and Preparing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0fae2343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading cleaned, labelled article data as a Pandas dataframe\n",
    "data = pd.read_csv(\"Labelled_VR_data_Oct2020_Jan2021_wfulltext.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4a9d3d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spltting the article data by news and opinion label\n",
    "news = data[data[\"Article Status\"] == \"News\"]\n",
    "opinion = data[data[\"Article Status\"] == \"Opinion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ca44f9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an array of news fulltext strings and another of opinion fulltext strings\n",
    "news_fulltext_arr = np.array(news[\"Full Text\"])\n",
    "opinion_fulltext_arr = np.array(opinion[\"Full Text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86798aa",
   "metadata": {},
   "source": [
    "# Determining Highly Predictive, Rule-Based Phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a815191",
   "metadata": {},
   "source": [
    "GOAL: Brainstorm highly predictive phrases to use a heuristics that would precede a feature-based classification step in the news vs opinion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9f315648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_op_diff(string, opinion_arr, news_arr):\n",
    "    \"\"\"Given an array of opinion articles, an array of news articles, and a search string,\n",
    "       Find how many opinion articles vs news articles the string appears in.\"\"\"\n",
    "    # Count how many opinion articles string appears in\n",
    "    opinion_count = 0\n",
    "    for article in opinion_arr:\n",
    "        if string in article.lower():\n",
    "            opinion_count+=1\n",
    "    # Count how many news articles string appears in\n",
    "    news_count = 0\n",
    "    for article in news_arr:\n",
    "        if string in article.lower():\n",
    "            news_count += 1\n",
    "    # Report this data\n",
    "    print('\"' + string + '\"' + \" appears in \" + str(opinion_count) + \"/\" + str(len(opinion_arr)) + \" opinion articles and \" \n",
    "          + str(news_count) + \"/\" + str(len(news_arr)) + \" news articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ab0439cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial suggestions for good discriminatory phrases\n",
    "initial_try_words = [\"opinion\", \"analysis\", \"guest columnist\", \"letter to the editor\", \"letters to the editor\",\n",
    "                    \"editorial\", \"editors\", \"readers\", \"columnist\", \"special\", \"you\"] + [\"editor\", \"staff writer\",\n",
    "                    \"staff writers\",\"bureau\", \"news service\", \"contributing writer\", \"news group\",\"bureau chief\",\n",
    "                    \"contributed\", \"compiled by\", \"staff\",\"editor in chief\", \"editor-in-chief\", \"managing editor\", \n",
    "                    \"political editor\", \"editor-at-large\", \"correspondent\", \"yesterday\", \"last\", \"say\", \"some\", \n",
    "                    \"company\", \"official\", \"plan\", \"here\", \"mr\"]\n",
    "\n",
    "# My (Daniel's) suggestions for good discriminatory phrases\n",
    "daniels_try_words = [\"editor at large\", \"editor-at-large\", \"opinion by\", \"follow him on twitter\",\n",
    "                \"opinion piece\", \"the ap is solely responsible for this content\", \"this guide will\",\n",
    "                \"analysis by\", \"news by\", \"opinion section\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc732e7",
   "metadata": {},
   "source": [
    "### Domain Research on Newspaper Publications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e053f7",
   "metadata": {},
   "source": [
    "We suspect the most likely source of a strong predictive phrase has to do with the qualifications of the author, so I looked at the differences between reporters, editors, and columnists: <br />\n",
    "\n",
    "https://customerservice.globe.com/hc/en-us/articles/360020398232-What-is-the-difference-between-a-reporter-editor-and-columnist-<br />\n",
    "\n",
    "**Reporters**: \"gathers facts and information... reporter is supposed to provide objective observation\" (seems more like news)<br />\n",
    "\n",
    "**Editors**: \"assign reporters, decide which news events to cover, edit (revise)reporters' stories, decide what stories get published\" (seems more like news)<br />\n",
    "\n",
    "**Columnists**: \"gives opinions, usually his or her own. A columnist is expected to gather accurate information, just as a reporter does, and then comment on that information.\" (more like opinion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79032107",
   "metadata": {},
   "source": [
    "With this domain knowledge in mind, better search strings came out of the woodwork:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7e2745ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suggestions for good discriminatory phrases after research on how newspaper publication works\n",
    "informed_words = [\"reporter\", \"reporting by\", \"is a reporter\", \"reporter at\", \"reporter for\",\n",
    "                  \"editor\", \"editing by\", \"is an editor\", \"editor at\", \"editor for\", \"editorial\",\n",
    "                  \"columnist\", \"is a columnist\", \"columnist at\", \"columnist for\", \"guest columnist\",\n",
    "                  \"publisher\", \"publication\", \"this publication\", \n",
    "                  \"op-ed\", \"letters to the editor\", \"letter to the editor\", \"opposite editorial\",\n",
    "                  \"guest essay\", \"my opinion\", \"opinion columnist\", \"op-ed columnist\",\n",
    "                  \"opinion section\", \"this column\", \"opinion:\", \"produced by\", \"special thanks\", \n",
    "                  \"we'd like to hear\"]\n",
    "\n",
    "# Words that had the highest difference in frequency between news and opinion articles\n",
    "good_words = [\"reporting by\", \"is a reporter\", \"reporter at\", \"editing by\", \"is a columnist\",\n",
    "             \"columnist at\", \"colunmnist for\", \"guest columnist\", \"letters to the editor\",\n",
    "             \"op-ed columnist\", \"opinion section\", \"this column\", \"opinion:\", \"we'd like to hear\"]\n",
    "\n",
    "# Words that both had a high difference in frequency between neews and opinion articles\n",
    "# and occured enough that small sample size was not a concern\n",
    "best_words = [\"reporting by\",\"editing by\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5f726f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"reporting by\" appears in 1/606 opinion articles and 152/2945 news articles\n",
      "\"editing by\" appears in 1/606 opinion articles and 147/2945 news articles\n"
     ]
    }
   ],
   "source": [
    "# Show results for predictive power of the discriminatory phrases we came up with\n",
    "for try_word in best_words:\n",
    "    news_op_diff(try_word, opinion_fulltext_arr, news_fulltext_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cbdaa7",
   "metadata": {},
   "source": [
    "## Setting Up Shiny's Feature Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ebb0f04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_len(art_str):\n",
    "    \"\"\"\n",
    "    Returns the average sentence length measured in tokens (inverted).\n",
    "    \"\"\"\n",
    "    dots = [p for p in range(len(art_str)) if art_str[p] == \".\"]\n",
    "    sentences = [dots[i+1] - dots[i] for i in range(len(dots) - 1)]\n",
    "    return (1/np.average(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b3754838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_len(art_str):\n",
    "    \"\"\"\n",
    "    Returns the average token length measured in characters (inverted).\n",
    "    \"\"\"\n",
    "    wordList = re.sub(\"[^\\w]\", \" \",  art_str).split()\n",
    "    return 1/(np.average([len(w) for w in wordList]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "936e3b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "negations = [\"no\", \"not\", \"none\", \"no one\", \"nobody\", \"neither\", \"nowhere\", \"nothing\", \"never\"]\n",
    "neg_suffix = \"n't\"\n",
    "\n",
    "def negations_count(art_str):\n",
    "    wordList = re.sub(\"[^\\w]\", \" \",  art_str).split()\n",
    "    total = 0\n",
    "    for w in wordList:\n",
    "        if w.lower() in negations:\n",
    "            total += 1\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e383f811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation_count(art_str):\n",
    "    \"\"\"\n",
    "    Determines the numbers of exclamation marks, question marks, semicolons, and commas,\n",
    "    as compared to other punctuation symbols. \n",
    "    \"\"\"\n",
    "    count = [0] * 5\n",
    "    for i in range(len(art_str)):\n",
    "        if art_str[i] == \"?\":\n",
    "            count[0] += 1\n",
    "        elif art_str[i] == \"!\":\n",
    "            count[1] += 1\n",
    "        elif art_str[i] == \",\":\n",
    "            count[2] += 1\n",
    "        elif art_str[i] == \";\":\n",
    "            count[3] += 1\n",
    "        elif art_str[i] == \".\":\n",
    "            count[4] += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "82a0c7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "casual = ['after', 'because', 'insofar as', 'by', 'in turn', 'for', 'once', 'as a result', 'hence', 'in the end', \n",
    "          'by then', 'but', 'subsequently', 'as', 'therefore', 'unless', 'thus', 'accordingly', 'so that', 'since', \n",
    "          'consequently', 'indeed', 'ultimately', 'then', 'even though', 'now that', 'finally”,”hence”,”if', 'although', \n",
    "          'so', 'thereby', 'otherwise', 'due to', 'and', 'when']\n",
    "\n",
    "contrastive = ['nor', 'in fact', 'despite', 'equally', 'by comparison', 'contrast', 'by contrast', 'but', 'separately', \n",
    "               'whereas', 'rather', 'meanwhile', 'also', 'even so', 'though', 'unlike', 'however', 'or',  \n",
    "               'nevertheless', 'yet', 'even though', 'conversely', 'nonetheless', 'on the contrary', 'in contrast', 'while', \n",
    "               'likewise', 'instead', 'although', 'on the other hand', 'still', 'similarly', 'otherwise', 'actually', \n",
    "               'alternatively', 'on the one hand']\n",
    "\n",
    "temporal = [\"before\", \"after\", \"next\", \"shortly\", \"afterwards\", \"eventually\", \"firstly\", \"secondly\", \"previously\", \"meanwhile\",\n",
    "            \"finally\", \"while\", \"then\", \"earlier\", \"when\", \"initially\", \"soon\", \"suddenly\", \"until\", \"once\", \"recently\", \"already\", \"as\"]\n",
    "\n",
    "expansive = [\"also\", \"and\", \"as well as\", \"besides\", \"in addition\", \"furthermore\", \"in fact\", \"moreover\", \"additionally\",\n",
    "             \"too\", \"further\", \"or\", \"neither\", \"nor\", \"either\"]\n",
    "\n",
    "def connective_count(art_str):\n",
    "    # casual, contrastive, temporal, expansive\n",
    "    connectives = [0] * 4\n",
    "    wordList = re.sub(\"[^\\w]\", \" \",  art_str).split()\n",
    "    for w in wordList:\n",
    "        if w.lower() in casual:\n",
    "            connectives[0] += 1\n",
    "        elif w.lower() in contrastive:\n",
    "            connectives[1] += 1\n",
    "        elif w.lower() in temporal:\n",
    "            connectives[2] += 1\n",
    "        elif w.lower() in expansive:\n",
    "            connectives[3] += 1\n",
    "    return connectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "23c21ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_person = ['I', 'we', 'our', 'ourselves', 'us', 'me', 'my', 'mine', 'myself']\n",
    "\n",
    "second_person = ['you', 'yours', 'your', 'yourself', 'yourselves']\n",
    "\n",
    "third_person = ['he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', \n",
    "                'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves']\n",
    "\n",
    "def pronouns_count(art_str):\n",
    "    wordList = re.sub(\"[^\\w]\", \" \",  art_str).split()\n",
    "    pronoun_count = [0] * 3\n",
    "    for w in wordList:\n",
    "        if w.lower() in first_person:\n",
    "            pronoun_count[0] += 1\n",
    "        elif w.lower() in second_person:\n",
    "            pronoun_count[1] += 1\n",
    "        elif w.lower() in third_person:\n",
    "            pronoun_count[2] += 1\n",
    "    return pronoun_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "362ad812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_citation(art_str):\n",
    "    \"\"\"\n",
    "    Returns the citation length and frequency in the article. \n",
    "    \"\"\"\n",
    "    quotes = re.findall(r'\"(.*?)\"', art_str)\n",
    "    within_quotes = collections.Counter(\" \".join(quotes).lower().split())\n",
    "    num_citations = len(quotes)\n",
    "    avg_citation_len = np.average([len(q) for q in quotes])\n",
    "    return [num_citations, avg_citation_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a15afa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "modals = [\"can\", \"must\", \"may\", \"could\", \"might\", \"should\", \"would\", \"shall\", \"ought to\"]\n",
    "vos = [\"announce\", \"claim\", \"declare\", \"explain\", \"insist\", \"mention\", \"exclaim\", \"state\", \"say\", \"said\"]\n",
    "future_will = \"will\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5112c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_digits(art_str):\n",
    "    \"\"\"\n",
    "    Returns the frequency of digits in a text. \n",
    "    \"\"\"\n",
    "    return len(re.findall(\"[\\d]\",art_str))/len(art_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3fa3a343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shiny's feature extraction function\n",
    "def get_all_features(art_str):\n",
    "    counter = collections.Counter(art_str.lower().split())\n",
    "    num_words = sum([counter.get(w) for w in counter.keys()])\n",
    "    \n",
    "    questions, exclamations, semicolons, commas, periods = punctuation_count(art_str)\n",
    "    first_p, second_p, third_p = 0, 0, 0\n",
    "    num_modals, num_vos = 0, 0\n",
    "    num_casual, num_temporal, num_contrastive, num_expansive = 0, 0, 0, 0\n",
    "    digits = 0\n",
    "    num_future = counter.get(\"will\")\n",
    "    opinion_count, news_count = 0, 0\n",
    "    num_negation, negation_suffix = 0, 0\n",
    "    quotes = re.findall(r'\"(.*?)\"', art_str)\n",
    "    within_quotes = collections.Counter(\" \".join(quotes).lower().split())\n",
    "    num_citations = len(quotes)\n",
    "    avg_citation_len = np.average([len(q) for q in quotes])\n",
    "    sent_length = sent_len(art_str)\n",
    "    token_length = token_len(art_str)\n",
    "    \n",
    "    for w in counter.keys():\n",
    "        if w in vos:\n",
    "            num_vos += counter.get(w)\n",
    "        elif w in first_person:\n",
    "            first_p += counter.get(w)\n",
    "        elif w in second_person:\n",
    "            second_p += counter.get(w)\n",
    "        elif w in third_person:\n",
    "            third_p += counter.get(w)\n",
    "        elif w in modals:\n",
    "            num_modals += counter.get(w)\n",
    "        elif w in casual:\n",
    "            num_casual += counter.get(w)\n",
    "        elif w in temporal:\n",
    "            num_temporal += counter.get(w)\n",
    "        elif w in contrastive:\n",
    "            num_contrastive += counter.get(w)\n",
    "        elif w in expansive:\n",
    "            num_expansive += counter.get(w)\n",
    "        elif any(char.isdigit() for char in w):\n",
    "            digits += 1\n",
    "        elif w in opinion:\n",
    "            opinion_count += counter.get(w)\n",
    "        elif w in news:\n",
    "            news_count += counter.get(w)\n",
    "        elif \"n't\" in w:\n",
    "            negation_suffix += counter.get(w)\n",
    "        elif w in negations:\n",
    "            num_negation += counter.get(w)\n",
    "            \n",
    "    ling_features = [sent_length, token_length, first_p, second_p, third_p, \n",
    "                    questions, exclamations, semicolons, commas, periods, \n",
    "                    num_casual, num_temporal, num_contrastive, num_expansive, \n",
    "                    digits, num_modals, num_vos, num_future, \n",
    "                    opinion_count, news_count,\n",
    "                    num_negation, negation_suffix, num_citations, avg_citation_len, num_words]\n",
    "    \n",
    "    return ling_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "28dd0c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/opt/conda/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# Preparing to create a dataframe where each record is a full text, and each column is a feature\n",
    "\n",
    "# Collecting the label for each record in an array\n",
    "y = []\n",
    "for article_label in data[\"Article Status\"]:\n",
    "    y.append(article_label)\n",
    "y = np.array(y)\n",
    "\n",
    "# Collecting the features for each record in an array\n",
    "X = []\n",
    "for article in data[\"Full Text\"]:\n",
    "    article_features = get_all_features(article)\n",
    "    X.append(article_features)\n",
    "X = np.array(X)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3e87ed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a reference for the features and target variables we are considering\n",
    "X_cols = ['sent_length', 'token_length', 'first_p', 'second_p', 'third_p', \n",
    "                    'questions', 'exclamations', 'semicolons', 'commas', 'periods', \n",
    "                    'num_casual', 'num_temporal', 'num_contrastive', 'num_expansive', \n",
    "                    'digits', 'num_modals', 'num_vos', 'num_future', \n",
    "                    'opinion_count', 'news_count',\n",
    "                    'num_negation', 'negation_suffix', 'num_citations', 'avg_citation_len', 'num_words']\n",
    "y_col = ['art_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f45f5a73",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_length</th>\n",
       "      <th>token_length</th>\n",
       "      <th>first_p</th>\n",
       "      <th>second_p</th>\n",
       "      <th>third_p</th>\n",
       "      <th>questions</th>\n",
       "      <th>exclamations</th>\n",
       "      <th>semicolons</th>\n",
       "      <th>commas</th>\n",
       "      <th>periods</th>\n",
       "      <th>...</th>\n",
       "      <th>num_vos</th>\n",
       "      <th>num_future</th>\n",
       "      <th>opinion_count</th>\n",
       "      <th>news_count</th>\n",
       "      <th>num_negation</th>\n",
       "      <th>negation_suffix</th>\n",
       "      <th>num_citations</th>\n",
       "      <th>avg_citation_len</th>\n",
       "      <th>num_words</th>\n",
       "      <th>art_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.21707</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "      <td>133</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1514</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007716</td>\n",
       "      <td>0.200762</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>65.195122</td>\n",
       "      <td>1456</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021549</td>\n",
       "      <td>0.224333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>632</td>\n",
       "      <td>Opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007221</td>\n",
       "      <td>0.196564</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>113.4</td>\n",
       "      <td>784</td>\n",
       "      <td>Opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006043</td>\n",
       "      <td>0.197957</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>945</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  sent_length token_length first_p second_p third_p questions exclamations  \\\n",
       "0      0.0149      0.21707       1        2      44         0            0   \n",
       "1    0.007716     0.200762       9        3      51         1            0   \n",
       "2    0.021549     0.224333       1        0      21         0            0   \n",
       "3    0.007221     0.196564       5        0      20         0            0   \n",
       "4    0.006043     0.197957       1        0      20         0            0   \n",
       "\n",
       "  semicolons commas periods  ... num_vos num_future opinion_count news_count  \\\n",
       "0         78      3     133  ...       8          6             0          0   \n",
       "1         92      3      71  ...       2          2             0          0   \n",
       "2         30      1      80  ...       0          3             0          0   \n",
       "3         31      1      36  ...       1          3             0          0   \n",
       "4         50      0      36  ...      11          2             0          0   \n",
       "\n",
       "  num_negation negation_suffix num_citations avg_citation_len num_words  \\\n",
       "0            8               0             0              NaN      1514   \n",
       "1           10               2            41        65.195122      1456   \n",
       "2            2               0             0              NaN       632   \n",
       "3            6               2             5            113.4       784   \n",
       "4            8               0             0              NaN       945   \n",
       "\n",
       "  art_status  \n",
       "0       News  \n",
       "1       News  \n",
       "2    Opinion  \n",
       "3    Opinion  \n",
       "4       News  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe where each record is a full text, and each column is a feature\n",
    "\n",
    "data_wfeats = pd.DataFrame(X, columns=X_cols)\n",
    "data_wfeats['art_status'] = y\n",
    "data_wfeats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "afdf62d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_length</th>\n",
       "      <th>token_length</th>\n",
       "      <th>first_p</th>\n",
       "      <th>second_p</th>\n",
       "      <th>third_p</th>\n",
       "      <th>questions</th>\n",
       "      <th>exclamations</th>\n",
       "      <th>semicolons</th>\n",
       "      <th>commas</th>\n",
       "      <th>periods</th>\n",
       "      <th>...</th>\n",
       "      <th>num_vos</th>\n",
       "      <th>num_future</th>\n",
       "      <th>opinion_count</th>\n",
       "      <th>news_count</th>\n",
       "      <th>num_negation</th>\n",
       "      <th>negation_suffix</th>\n",
       "      <th>num_citations</th>\n",
       "      <th>avg_citation_len</th>\n",
       "      <th>num_words</th>\n",
       "      <th>art_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007716</td>\n",
       "      <td>0.200762</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>65.195122</td>\n",
       "      <td>1456</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007221</td>\n",
       "      <td>0.196564</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>113.4</td>\n",
       "      <td>784</td>\n",
       "      <td>Opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.009358</td>\n",
       "      <td>0.20407</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>667</td>\n",
       "      <td>Opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.010215</td>\n",
       "      <td>0.196864</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>30.75</td>\n",
       "      <td>1318</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.014028</td>\n",
       "      <td>0.203455</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>103</td>\n",
       "      <td>Opinion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  sent_length token_length first_p second_p third_p questions exclamations  \\\n",
       "1    0.007716     0.200762       9        3      51         1            0   \n",
       "3    0.007221     0.196564       5        0      20         0            0   \n",
       "5    0.009358      0.20407      15        4       9         0            0   \n",
       "6    0.010215     0.196864       0        2      25         1            0   \n",
       "7    0.014028     0.203455       1        0       0         0            0   \n",
       "\n",
       "  semicolons commas periods  ... num_vos num_future opinion_count news_count  \\\n",
       "1         92      3      71  ...       2          2             0          0   \n",
       "3         31      1      36  ...       1          3             0          0   \n",
       "5         27      1      38  ...       2          9             0          0   \n",
       "6         66      0      88  ...       6          2             0          0   \n",
       "7          5      0       8  ...       0          1             0          0   \n",
       "\n",
       "  num_negation negation_suffix num_citations avg_citation_len num_words  \\\n",
       "1           10               2            41        65.195122      1456   \n",
       "3            6               2             5            113.4       784   \n",
       "5            9               1             1             18.0       667   \n",
       "6            2               3             8            30.75      1318   \n",
       "7            1               0             2             28.0       103   \n",
       "\n",
       "  art_status  \n",
       "1       News  \n",
       "3    Opinion  \n",
       "5    Opinion  \n",
       "6       News  \n",
       "7    Opinion  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping records from this dataframe where feature values are missing\n",
    "data_wfeats = data_wfeats.dropna()\n",
    "data_wfeats.head()\n",
    "\n",
    "#FIXME oh my that's quite a lot lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e49d5ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train test split for articles in our dataset\n",
    "train, test = train_test_split(data_wfeats, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b57af0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the data matrix and label vector for train and test data sets\n",
    "X_train = train[X_cols].to_numpy()\n",
    "y_train = train[y_col].to_numpy().flatten()\n",
    "\n",
    "X_test = test[X_cols].to_numpy()\n",
    "y_test = test[y_col].to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b2250150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting a support vector classifier on X_train and y_train\n",
    "svc = svm.SVC(kernel='linear')\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "cab0b4c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7649685727283699"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Evaluating SVM performance on test data\n",
    "y_pred = svc.predict(X_test)\n",
    "y_true = y_test\n",
    "\n",
    "# Initial f1 score\n",
    "f1_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da456e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
